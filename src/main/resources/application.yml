application:
  input.topic: env.app.person
  output.topic: env.app.person-transform
  failure.output.topic: env.app.failures
  state.store.cleanup: false
  in.memory.state.stores: false

# Kafka Streams related properties
kafka:
  producer:
    application.id: error-producer
    bootstrap.servers: localhost:9092
    security.protocol: SASL_SSL
    sasl.mechanism: PLAIN
    sasl.jaas.config: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="kafka" password="kafka-secret";'
    key.serializer: org.apache.kafka.common.serialization.LongSerializer
    value.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
    ssl.truststore.location: /Users/markchristiansen/repos/github.com/objectpartners/confluent-platform-toolkit/certs/kafka1.mycompany.com.truststore.jks
    ssl.truststore.password: serverpassword
    schema.registry.url: https://localhost:8081
    schema.registry.ssl.truststore.location: /Users/markchristiansen/repos/github.com/objectpartners/confluent-platform-toolkit/certs/kafka1.mycompany.com.truststore.jks
    schema.registry.ssl.truststore.password: serverpassword
    basic.auth.credentials.source: USER_INFO
    basic.auth.user.info: admin:admin-secret
  streams:
    application.id: streams-app
    group.id: streams-group
    acks: all
    auto.reset.offset: earliest
    # broker connection configuration
    bootstrap.servers: localhost:9092
    security.protocol: SASL_SSL
    sasl.mechanism: PLAIN
    sasl.jaas.config: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="kafka" password="kafka-secret";'
    default.key.serde: io.confluent.kafka.streams.serdes.avro.GenericAvroSerde
    default.value.serde: io.confluent.kafka.streams.serdes.avro.GenericAvroSerde
    default.timestamp.extractor: org.apache.kafka.streams.processor.WallclockTimestampExtractor
    default.deserialization.exception.handler: org.apache.kafka.streams.errors.LogAndFailExceptionHandler
    default.production.exception.handler: org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
    # for changelog topics and repartition topics, match other topics to guarantee fault tolerance
    replication.factor: -1
    request.timeout.ms: 60000
    session.timeout.ms: 30000
    isolation.level: read_committed
    processing.guarantee: exactly_once_beta
    retries: 2147483647
    enabled.idempotence: true
    max.in.flight.requests.per.connection: 1
    buffered.records.per.partition: 1000
    commit.interval.ms: 5000
    num.stream.threads: 1
    poll.ms: 100
    cache.max.bytes.buffering: 10485760
    # state store configuration
    state.dir: /tmp/streams
    num.standby.replicas: 0
    min.insync.replicas: 0
    # schema registry configuration
    schema.registry.url: https://localhost:8081
    schema.registry.auth: true
    schema.cache.capacity: 2000
    basic.auth.credentials.source: USER_INFO
    basic.auth.user.info: admin:admin-secret
    #key.subject.name.strategy: io.confluent.kafka.serializers.subject.RecordNameStrategy
    #value.subject.name.strategy: io.confluent.kafka.serializers.subject.RecordNameStrategy
    topology.optimization: all
    ssl.truststore.location: /Users/markchristiansen/repos/github.com/objectpartners/confluent-platform-toolkit/certs/kafka1.mycompany.com.truststore.jks
    ssl.truststore.password: serverpassword
    schema.registry.ssl.truststore.location: /Users/markchristiansen/repos/github.com/objectpartners/confluent-platform-toolkit/certs/kafka1.mycompany.com.truststore.jks
    schema.registry.ssl.truststore.password: serverpassword
    auto.register.schemas: false
    use.latest.version: true
    latest.compatibility.strict: false

